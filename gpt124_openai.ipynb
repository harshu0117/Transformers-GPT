{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvfViV6A_QtU"
   },
   "source": [
    "## IMPLEMENTING A GPT MODEL FROM SCRATCH TO GENERATE TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hv3YYBI8_z0u"
   },
   "source": [
    "### STEP 1: TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmg5sasW_0RQ",
    "outputId": "516bb534-d7dc-4957-f04b-7fc3a87c9719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZC6-Y3KDOrU"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCbOLbJB8VDi"
   },
   "source": [
    "## THE FINAL GPT CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9yd5s92jB0jB"
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxWBP9cSBNoY"
   },
   "source": [
    "### THE BUILDING BLOCKS: LAYER NORMALIZATION, GELU AND FEED-FORWARD NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DaOyvK895TY"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Vld9pM7B9Jh"
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
    "            GELU(), ## Activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbZQ9bMv8svh"
   },
   "source": [
    "## THE TRANSFORMER BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfMlNqon7UA7"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MjT0I_GxCJp_"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        # 2*4*768\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "        # 2*4*768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AQA92sb8fZp"
   },
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1BDM6NF8dyQ",
    "outputId": "8702b91a-e258-4456-baf8-83653b93c05a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GM0hty5W8o1A",
    "outputId": "0ce14662-6841-4302-d9b6-fcbf1693a097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8jLyFJ5BWqa"
   },
   "source": [
    "## GENERATING TEXT FROM OUTPUT TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nzthkn5lBlEA"
   },
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "\n",
    "    ###Input batch:\n",
    "    ###tensor([[6109, 3626, 6100,  345],\n",
    "            ##[6109, 1110, 6622,  257]])\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
    "\n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1OvTMtVCElt",
    "outputId": "f33e29fa-c6d6-405f-dc18-14f1220f0bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0o1w9kG2CF7H",
    "outputId": "2cb90da9-5f8f-43f3-c843-37fc084ddece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() #A\n",
    "#model = GPTModel(GPT_CONFIG_124M)\n",
    "out = generate_text_simple(\n",
    "model=model,\n",
    "idx=encoded_tensor,\n",
    "max_new_tokens=6,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04rCtSqvCUCn"
   },
   "source": [
    "### Our first output from our GPT ( NOT YET TRAINED ) so its obivious to get non sense outputs , but still we are getting something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3Dgp9PACReH",
    "outputId": "cf117ffe-f350-4e32-e185-0fa3d54f97c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SG3l3IDC1MS"
   },
   "source": [
    "### Thats okay, let's train it then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ceSXSRiMDAlF",
    "outputId": "e85b03b2-e0d9-4562-cedf-4255f12d368d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMTssXQrDoWy"
   },
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beXCBtVKG1E6"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3StYU23HHKq"
   },
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7bnFoEkHbTK",
    "outputId": "bf60435a-5f35-4082-9ac6-afe40cf8c848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough tokens for the validation loader. Try to lower the `GPT_CONFIG_124M['context_length']` or decrease the `training_ratio`\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4eOTiYJHmd3",
    "outputId": "b75dbf43-5aa4-40db-c241-c8f183c8fd96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "\n",
      "Validation loader:\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6JSIr9_JPan"
   },
   "source": [
    "### Here we can see that , the train data is not big enough so we are lowering our GPTs context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQ31T0wZH0LW"
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDdLtfW5H_PZ"
   },
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HcG__F9ILPN",
    "outputId": "ca334865-7ba8-41ed-c8d4-f106c4bddb0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FlBRl_s1IKqI",
    "outputId": "51d368ec-009c-442c-d403-211a7c7e8a8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1579WlmVKLQx"
   },
   "source": [
    "### Okay as we now implemented the data loaders and the data is ready to feed in , but how do we know that our model is learning ??\n",
    "\n",
    "### Thats where Loss functions comes in , we are using cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75juXiHaKAAu"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FX8jNWlLKz-W",
    "outputId": "8170440d-3823-43e0-ad99-9fcf09c553d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98850186665853\n",
      "Validation loss: 10.990342140197754\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Py0zkRPoNJsc"
   },
   "source": [
    "### The Above is the intial loss , lets see how we the loss function decreases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1M7bfgjPNeXF"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQvnR-KwNTfS"
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "biFx9saeNoX8",
    "outputId": "806fe07f-c39c-446b-8f14-6796ff5ca554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.768, Val loss 9.930\n",
      "Ep 1 (Step 000005): Train loss 8.069, Val loss 8.336\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.726, Val loss 7.053\n",
      "Ep 2 (Step 000015): Train loss 6.102, Val loss 6.605\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.604, Val loss 6.507\n",
      "Ep 3 (Step 000025): Train loss 5.422, Val loss 6.389\n",
      "Every effort moves you, and to the to the of the to the, and I had. Gis, and, and, and, and, and, and I had the, and, and, and, and, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train loss 5.007, Val loss 6.280\n",
      "Ep 4 (Step 000035): Train loss 4.585, Val loss 6.304\n",
      "Every effort moves you.  \"I the picture.                    \"I\"I the picture\"I had the the honour of the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 4.112, Val loss 6.165\n",
      "Every effort moves you know                                                 \n",
      "Ep 6 (Step 000045): Train loss 3.575, Val loss 6.172\n",
      "Ep 6 (Step 000050): Train loss 3.077, Val loss 6.144\n",
      "Every effort moves you know the was his a little the.  \"I had the last word.           \"Oh, and I had a little.   \"I looked, and I had a little of\n",
      "Ep 7 (Step 000055): Train loss 2.608, Val loss 6.183\n",
      "Ep 7 (Step 000060): Train loss 2.214, Val loss 6.128\n",
      "Every effort moves you know the picture to have been too--I felt, and Mrs.  \"I was no--and the fact, and that, and I was his pictures.  \"I looked up his pictures--and--because he was a little\n",
      "Ep 8 (Step 000065): Train loss 1.762, Val loss 6.162\n",
      "Ep 8 (Step 000070): Train loss 1.397, Val loss 6.229\n",
      "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"I looked up, and the fact, and to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.086, Val loss 6.268\n",
      "Ep 9 (Step 000080): Train loss 0.824, Val loss 6.298\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"I looked, and that, and I remember getting off a prodigious phrase about the honour being _mine_--because he's the first\n",
      "Ep 10 (Step 000085): Train loss 0.615, Val loss 6.382\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 11 (Step 000090): Train loss 0.469, Val loss 6.408\n",
      "Ep 11 (Step 000095): Train loss 0.347, Val loss 6.435\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 12 (Step 000100): Train loss 0.251, Val loss 6.528\n",
      "Ep 12 (Step 000105): Train loss 0.202, Val loss 6.549\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, moved aside a _jardiniere_ full of\n",
      "Ep 13 (Step 000110): Train loss 0.164, Val loss 6.633\n",
      "Ep 13 (Step 000115): Train loss 0.134, Val loss 6.733\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 14 (Step 000120): Train loss 0.108, Val loss 6.806\n",
      "Ep 14 (Step 000125): Train loss 0.083, Val loss 6.819\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 15 (Step 000130): Train loss 0.073, Val loss 6.918\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 16 (Step 000135): Train loss 0.061, Val loss 6.881\n",
      "Ep 16 (Step 000140): Train loss 0.112, Val loss 7.025\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, moved aside a _jardiniere_ full of\n",
      "Ep 17 (Step 000145): Train loss 0.059, Val loss 6.973\n",
      "Ep 17 (Step 000150): Train loss 0.043, Val loss 6.989\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 18 (Step 000155): Train loss 0.039, Val loss 7.064\n",
      "Ep 18 (Step 000160): Train loss 0.035, Val loss 7.048\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 19 (Step 000165): Train loss 0.028, Val loss 7.073\n",
      "Ep 19 (Step 000170): Train loss 0.024, Val loss 7.134\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 20 (Step 000175): Train loss 0.024, Val loss 7.146\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Training completed in 1.19 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 20\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=10,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "1BB63z8sN8qh",
    "outputId": "b75572d7-9560-4fb5-f5cf-882a248e8bdc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLUh2b-ZOoaa",
    "outputId": "63e99832-7a6f-4a3c-96fe-a514f5c56b6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am\n",
      "Hello, I am Guminois employees teacher\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "# print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
    "# print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = generate_text_simple(\n",
    "model=model,\n",
    "idx=encoded_tensor,\n",
    "max_new_tokens=4,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "# print(\"Output:\", out)\n",
    "# print(\"Output length:\", len(out[0]))\n",
    "\n",
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(start_context)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sI0E15xRVWr"
   },
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLSlLH_XQBEc"
   },
   "source": [
    "### So yes, over model is slightly better now. But this is no where near to a bare minimum model , so we are taking the weights from the OPEN AI , which they have publically released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93_HMmViRGrp"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow>=2.15.0 tqdm>=4.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_7LP4n0Rly5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "RXIeLlUJbnpB"
   },
   "outputs": [],
   "source": [
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model sizepython -c \"import tensorflow as tf; print(tf.__version__)\"\n",
    "\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path)\n",
    "\n",
    "    ## We have reached here until now ---> we have downloaded the files on our local machine.\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "def download_file(url, destination):\n",
    "    try:\n",
    "        # Send a GET request to download the file, disabling SSL verification\n",
    "        response = requests.get(url, stream=True, verify=False)\n",
    "\n",
    "        # Get the total file size from headers, defaulting to 0 if not present\n",
    "        file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "        # Check if file exists and has the same size\n",
    "        if os.path.exists(destination):\n",
    "            file_size_local = os.path.getsize(destination)\n",
    "            if file_size == file_size_local:\n",
    "                print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                return\n",
    "\n",
    "        # Define the block size for reading the file\n",
    "        block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "        # Initialize the progress bar with total file size\n",
    "        progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "            # Open the destination file in binary write mode\n",
    "            with open(destination, \"wb\") as file:\n",
    "                # Iterate over the file data in chunks\n",
    "                for chunk in response.iter_content(block_size):\n",
    "                    progress_bar.update(len(chunk))  # Update progress bar\n",
    "                    file.write(chunk)  # Write the chunk to the file\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading the file: {e}\")\n",
    "        print(f\"Please check the URL: {url}\")\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4sl8Y0qb_p8",
    "outputId": "6e1deca9-638b-4444-8abc-6d9ad4e750c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "checkpoint: 100%|| 77.0/77.0 [00:00<00:00, 116kiB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "encoder.json: 100%|| 1.04M/1.04M [00:01<00:00, 654kiB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "hparams.json: 100%|| 90.0/90.0 [00:00<00:00, 212kiB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.data-00000-of-00001: 100%|| 498M/498M [02:38<00:00, 3.14MiB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.index: 100%|| 5.21k/5.21k [00:00<00:00, 6.56MiB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.meta: 100%|| 471k/471k [00:00<00:00, 472kiB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "vocab.bpe: 100%|| 456k/456k [00:01<00:00, 381kiB/s]\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "vfLxSDIWUXBQ"
   },
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "2gDMLvvjUckT"
   },
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "OHqd1DrYUuYo"
   },
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "rpVCQl_IagjS"
   },
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "akhPlKbcUjtF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "_nRtSdi3U11D"
   },
   "outputs": [],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OX6WcKjKU-yj",
    "outputId": "7f9216d3-9c69-47bf-dc9b-148eb1a428a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you forward. If a situation requires urgent attention and you don't feel well-adjusted to handle things this is not always a good\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
